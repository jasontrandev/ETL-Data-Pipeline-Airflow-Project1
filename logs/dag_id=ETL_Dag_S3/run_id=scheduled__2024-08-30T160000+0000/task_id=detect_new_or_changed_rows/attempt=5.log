[2024-08-30T17:39:16.179+0000] {task_command.py:423} INFO - Running <TaskInstance: ETL_Dag_S3.detect_new_or_changed_rows scheduled__2024-08-30T16:00:00+00:00 [restarting]> on host 00c82e2512e7
[2024-08-30T17:39:16.760+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='jasontran' AIRFLOW_CTX_DAG_ID='ETL_Dag_S3' AIRFLOW_CTX_TASK_ID='detect_new_or_changed_rows' AIRFLOW_CTX_EXECUTION_DATE='2024-08-30T16:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='5' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-30T16:00:00+00:00'
[2024-08-30T17:39:16.811+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
[2024-08-30T17:39:18.292+0000] {logging_mixin.py:188} INFO - Succesfully read data from AWS S3
[2024-08-30T17:39:18.312+0000] {connection.py:370} INFO - Snowflake Connector for Python Version: 3.6.0, Python Version: 3.8.18, Platform: Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
[2024-08-30T17:39:18.315+0000] {connection.py:1171} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-08-30T17:39:24.802+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1305, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 729, in _post_request
    ret = self.fetch(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 838, in fetch
    ret = self._request_exec_wrapper(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 974, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 879, in _request_exec_wrapper
    return_object = self._request_exec(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 1188, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 1114, in _request_exec
    raise OperationalError(
snowflake.connector.errors.OperationalError: 251012: 251012: Login request is retryable. Will be handled by authenticator

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/includes/emp_dim_insert_update.py", line 27, in detect_new_or_changed_rows
    conn = sc.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/__init__.py", line 54, in Connect
    return SnowflakeConnection(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 413, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 703, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1006, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1277, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1349, in _authenticate
    raise auth_op from e
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1326, in _authenticate
    auth_instance.handle_timeout(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/auth/by_plugin.py", line 212, in handle_timeout
    raise error
snowflake.connector.errors.OperationalError: 250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting
[2024-08-30T17:39:24.956+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ETL_Dag_S3, task_id=detect_new_or_changed_rows, execution_date=20240830T160000, start_date=20240830T173915, end_date=20240830T173924
[2024-08-30T17:39:25.481+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 118 for task detect_new_or_changed_rows (250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting; 262)
[2024-08-30T17:39:45.787+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ETL_Dag_S3.detect_new_or_changed_rows scheduled__2024-08-30T16:00:00+00:00 [queued]>
[2024-08-30T17:39:45.804+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ETL_Dag_S3.detect_new_or_changed_rows scheduled__2024-08-30T16:00:00+00:00 [queued]>
[2024-08-30T17:39:45.805+0000] {taskinstance.py:2170} INFO - Starting attempt 5 of 10
[2024-08-30T17:39:45.837+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): detect_new_or_changed_rows> on 2024-08-30 16:00:00+00:00
[2024-08-30T17:39:45.846+0000] {standard_task_runner.py:60} INFO - Started process 291 to run task
[2024-08-30T17:39:45.855+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'ETL_Dag_S3', 'detect_new_or_changed_rows', 'scheduled__2024-08-30T16:00:00+00:00', '--job-id', '121', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag_s3.py', '--cfg-path', '/tmp/tmpg0595439']
[2024-08-30T17:39:45.859+0000] {standard_task_runner.py:88} INFO - Job 121: Subtask detect_new_or_changed_rows
[2024-08-30T17:39:45.958+0000] {task_command.py:423} INFO - Running <TaskInstance: ETL_Dag_S3.detect_new_or_changed_rows scheduled__2024-08-30T16:00:00+00:00 [running]> on host 00c82e2512e7
[2024-08-30T17:39:46.106+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='jasontran' AIRFLOW_CTX_DAG_ID='ETL_Dag_S3' AIRFLOW_CTX_TASK_ID='detect_new_or_changed_rows' AIRFLOW_CTX_EXECUTION_DATE='2024-08-30T16:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='5' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-08-30T16:00:00+00:00'
[2024-08-30T17:39:46.139+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
[2024-08-30T17:39:47.105+0000] {logging_mixin.py:188} INFO - Succesfully read data from AWS S3
[2024-08-30T17:39:47.109+0000] {connection.py:370} INFO - Snowflake Connector for Python Version: 3.6.0, Python Version: 3.8.18, Platform: Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
[2024-08-30T17:39:47.111+0000] {connection.py:1171} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-08-30T17:39:49.523+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1305, in _authenticate
    auth.authenticate(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/auth/_auth.py", line 250, in authenticate
    ret = self._rest._post_request(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 729, in _post_request
    ret = self.fetch(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 838, in fetch
    ret = self._request_exec_wrapper(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 974, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 879, in _request_exec_wrapper
    return_object = self._request_exec(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 1188, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/network.py", line 1114, in _request_exec
    raise OperationalError(
snowflake.connector.errors.OperationalError: 251012: 251012: Login request is retryable. Will be handled by authenticator

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/includes/emp_dim_insert_update.py", line 27, in detect_new_or_changed_rows
    conn = sc.connect(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/__init__.py", line 54, in Connect
    return SnowflakeConnection(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 413, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 703, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1006, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1277, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1349, in _authenticate
    raise auth_op from e
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/connection.py", line 1326, in _authenticate
    auth_instance.handle_timeout(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/auth/by_plugin.py", line 212, in handle_timeout
    raise error
snowflake.connector.errors.OperationalError: 250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting
[2024-08-30T17:39:49.540+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=ETL_Dag_S3, task_id=detect_new_or_changed_rows, execution_date=20240830T160000, start_date=20240830T173945, end_date=20240830T173949
[2024-08-30T17:39:49.586+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 121 for task detect_new_or_changed_rows (250001: 250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting; 291)
[2024-08-30T17:39:49.609+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-08-30T17:39:49.685+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
