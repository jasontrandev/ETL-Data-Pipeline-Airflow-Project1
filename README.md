# ETL-Data-Pipeline-using-Airflow
Build an ETL Data Pipelines that uses Airflow DAGs to extract employeesâ€™ data from PostgreSQL Schemas, load it into AWS Data Lake, then transform it with Python script, and finally load it into Snowflake Data warehouse using SCD type 2.
